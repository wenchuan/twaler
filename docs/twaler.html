<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>


<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="index,nofollow">

<title>twaler - Untitled Wiki</title>
<script type="text/javascript" src="twaler_files/common.js"></script>

<script type="text/javascript">
<!--
var search_hint = "Search";
//-->
</script>

<script type="text/javascript">
<!-- // GUI edit link and i18n
var gui_editor_link_href = "/twaler?action=edit&editor=gui";
var gui_editor_link_text = "Edit (GUI)";
//-->
</script>

<link rel="stylesheet" type="text/css" charset="utf-8" media="all" href="twaler_files/common.css">
<link rel="stylesheet" type="text/css" charset="utf-8" media="screen" href="twaler_files/screen.css">
<link rel="stylesheet" type="text/css" charset="utf-8" media="print" href="twaler_files/print.css">
<link rel="stylesheet" type="text/css" charset="utf-8" media="projection" href="twaler_files/projection.css">

<!-- css only for MS IE6/IE7 browsers -->
<!--[if lt IE 8]>
   <link rel="stylesheet" type="text/css" charset="utf-8" media="all" href="/moin_static191/modern/css/msie.css">
<![endif]-->



<link rel="alternate" type="application/wiki" title="Edit" href="http://wiki.cs.ucla.edu/twaler?action=edit">

<link rel="Start" href="http://wiki.cs.ucla.edu/home">
<link rel="Alternate" title="Wiki Markup" href="http://wiki.cs.ucla.edu/twaler?action=raw">
<link rel="Alternate" media="print" title="Print View" href="http://wiki.cs.ucla.edu/twaler?action=print">
<link rel="Appendix" title="tut1.png" href="http://wiki.cs.ucla.edu/twaler?action=AttachFile&amp;do=view&amp;target=tut1.png">
<link rel="Appendix" title="twaler_state_diagram.jpg" href="http://wiki.cs.ucla.edu/twaler?action=AttachFile&amp;do=view&amp;target=twaler_state_diagram.jpg">
<link rel="Appendix" title="twalergraph.jpg" href="http://wiki.cs.ucla.edu/twaler?action=AttachFile&amp;do=view&amp;target=twalergraph.jpg">
<link rel="Search" href="http://wiki.cs.ucla.edu/FindPage">
<link rel="Index" href="http://wiki.cs.ucla.edu/TitleIndex">
<link rel="Glossary" href="http://wiki.cs.ucla.edu/WordIndex">
<link rel="Help" href="http://wiki.cs.ucla.edu/HelpOnFormatting">
</head><body dir="ltr" lang="en">

<div id="header">
<div id="logo"><a href="http://wiki.cs.ucla.edu/home"><img src="twaler_files/wikics.png" alt="Wiki CS Logo"></a></div>

<form id="searchform" method="get" action="/twaler">
<div>
<input name="action" value="fullsearch" type="hidden">
<input name="context" value="180" type="hidden">
<label style="display: none;" for="searchinput">Search:</label>
<input id="searchinput" name="value" value="" size="20" onfocus="searchFocus(this)" onblur="searchBlur(this)" onkeyup="searchChange(this)" onchange="searchChange(this)" alt="Search" type="text">
<input id="titlesearch" name="titlesearch" value="Titles" alt="Search Titles" type="submit">
<input id="fullsearch" name="fullsearch" value="Text" alt="Search Full Text" type="submit">
</div>
</form>
<script type="text/javascript">
<!--// Initialize search form
var f = document.getElementById('searchform');
f.getElementsByTagName('label')[0].style.display = 'none';
var e = document.getElementById('searchinput');
searchChange(e);
searchBlur(e);
//-->
</script>

<ul id="username"><li><a class="nonexistent" href="http://wiki.cs.ucla.edu/AlexanderLiu" id="userhome" title="AlexanderLiu @ Self">AlexanderLiu</a></li><li><a href="http://wiki.cs.ucla.edu/twaler?action=userprefs" id="userprefs" rel="nofollow">Settings</a></li><li><a href="http://wiki.cs.ucla.edu/twaler?action=logout&amp;logout=logout" id="logout" rel="nofollow">Logout</a></li></ul>
<div id="locationline">


<ul id="pagelocation">
<li><a class="backlink" href="http://wiki.cs.ucla.edu/twaler?action=fullsearch&amp;context=180&amp;value=linkto%3A%22twaler%22" rel="nofollow" title="Click to do a full-text search for this title">twaler</a></li>
</ul>

</div>

<ul id="pagetrail">
<li><a href="http://wiki.cs.ucla.edu/Snorg">Snorg</a></li><li><a href="http://wiki.cs.ucla.edu/Snorg/DataSets">Snorg/DataSets</a></li><li><a href="http://wiki.cs.ucla.edu/Snorg/Code">Snorg/Code</a></li><li><a href="http://wiki.cs.ucla.edu/twaler">twaler</a></li>
</ul>

<ul id="navibar">
<li class="wikilink"><a href="http://wiki.cs.ucla.edu/RecentChanges">RecentChanges</a></li><li class="wikilink"><a href="http://wiki.cs.ucla.edu/FindPage">FindPage</a></li><li class="wikilink"><a href="http://wiki.cs.ucla.edu/HelpContents">HelpContents</a></li><li class="current"><a href="http://wiki.cs.ucla.edu/twaler">twaler</a></li>
</ul>

<div id="pageline"><hr style="display: none;"></div>

<ul class="editbar"><li><a href="http://wiki.cs.ucla.edu/twaler?action=edit&amp;editor=text" name="texteditlink" rel="nofollow">Edit (Text)</a></li><li><a href="http://wiki.cs.ucla.edu/twaler?action=edit&amp;editor=gui">Edit (GUI)</a></li><li class="toggleCommentsButton" style="display: none;"><a href="#" class="nbcomment" onclick="toggleComments();return false;">Comments</a></li><li><a class="nbinfo" href="http://wiki.cs.ucla.edu/twaler?action=info" rel="nofollow">Info</a></li><li><a class="nbsubscribe" href="http://wiki.cs.ucla.edu/twaler?action=subscribe" rel="nofollow">Subscribe</a></li><li><a class="nbquicklink" href="http://wiki.cs.ucla.edu/twaler?action=quicklink" rel="nofollow">Add Link</a></li><li><a class="nbattachments" href="http://wiki.cs.ucla.edu/twaler?action=AttachFile" rel="nofollow">Attachments</a></li><li>
<form class="actionsmenu" method="get" action="/twaler">
<div>
    
    <select name="action" onchange="if ((this.selectedIndex != 0) &amp;&amp;
                      (this.options[this.selectedIndex].disabled == false)) {
                this.form.submit();
            }
            this.selectedIndex = 0;">
        <option value="show">More Actions:</option><option value="raw">Raw Text</option>
<option value="print">Print View</option>
<option value="RenderAsDocbook">Render as Docbook</option>
<option value="refresh">Delete Cache</option>
<option value="show" disabled="disabled" class="disabled">------------------------</option>
<option value="SpellCheck">Check Spelling</option>
<option value="LikePages">Like Pages</option>
<option value="LocalSiteMap">Local Site Map</option>
<option value="show" disabled="disabled" class="disabled">------------------------</option>
<option value="RenamePage">Rename Page</option>
<option value="DeletePage">Delete Page</option>
<option value="show" disabled="disabled" class="disabled">------------------------</option>
<option value="SubscribeUser">Subscribe User</option>
<option value="show" disabled="disabled" class="disabled">------------------------</option>
<option value="show" disabled="disabled" class="disabled">Remove Spam</option>
<option value="revert">Revert to this revision</option>
<option value="PackagePages">Package Pages</option>
<option value="SyncPages">Sync Pages</option>
<option value="show" disabled="disabled" class="disabled">------------------------</option>
<option value="Load">Load</option>
<option value="Save">Save</option>
<option value="SlideShow">SlideShow</option>
    </select>
    
    
</div>
<script type="text/javascript">
<!--// Init menu
actionsMenuInit('More Actions:');
//-->
</script>
</form>
</li></ul>

</div>

<div id="page" dir="ltr" lang="en">
<div dir="ltr" id="content" lang="en"><span class="anchor" id="top"></span>
<span class="anchor" id="line-1"></span><p class="line867">
</p><h1 id="Twaler">Twaler</h1>
<span class="anchor" id="line-2"></span><p class="line874">A set of tools to crawl data from Twitter using the Twitter API. <span class="anchor" id="line-3"></span><span class="anchor" id="line-4"></span></p><p class="line867">
</p><h3 id="Table_Of_Contents">Table Of Contents</h3>
<span class="anchor" id="line-5"></span><ul><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#Description">Description</a> <span class="anchor" id="line-6"></span></p></li><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#Files">Files</a> <span class="anchor" id="line-7"></span></p><ul><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#crawl.py">crawl.py</a> <span class="anchor" id="line-8"></span></p></li><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#process_crawl.py">process_crawl.py</a> <span class="anchor" id="line-9"></span></p></li><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#load_crawl.py">load_crawl.py</a> <span class="anchor" id="line-10"></span></p></li><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#generate_seeds.py">generate_seeds.py</a> <span class="anchor" id="line-11"></span></p></li><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#config.py">config.py</a> <span class="anchor" id="line-12"></span></p></li></ul></li><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#Usage_Example">Usage Example</a> <span class="anchor" id="line-13"></span></p></li><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#Getting_the_Latest_Version">Getting the Latest Version</a> <span class="anchor" id="line-14"></span><span class="anchor" id="line-15"></span></p></li></ul><p class="line867"><span class="anchor" id="Description"></span> <span class="anchor" id="line-16"></span><span class="anchor" id="line-17"></span></p><p class="line867">
</p><h2 id="Description-1">Description</h2>
<span class="anchor" id="line-18"></span><p class="line874">The generalized workflow is as follows (graph shown below): <span class="anchor" id="line-19"></span><span class="anchor" id="line-20"></span></p><ol type="1"><li><p class="line891"><em><a href="http://wiki.cs.ucla.edu/twaler#crawl.py">crawl.py</a></em> goes through a list of seeds (user_id or list_ids) and downloads the XML files through the REST API <span class="anchor" id="line-21"></span></p></li><li><p class="line891"><em><a href="http://wiki.cs.ucla.edu/twaler#process_crawl.py">process_crawl.py</a></em> processes the XML files downloaded and formats them into tsv files for easy of inserting into the database <span class="anchor" id="line-22"></span></p></li><li><p class="line891"><em><a href="http://wiki.cs.ucla.edu/twaler#load_crawl.py">load_crawl.py</a></em> loads all the tsv files into the twaler MySQL database <span class="anchor" id="line-23"></span></p></li><li><p class="line891"><em><a href="http://wiki.cs.ucla.edu/twaler#generate_seeds.py">generate_seeds.py</a></em> goes through the database and determines the next set of seeds to crawl <span class="anchor" id="line-24"></span><span class="anchor" id="line-25"></span></p></li></ol><p class="line867"><img alt="twalergraph.jpg" class="attachment" src="twaler_files/twaler.jpeg" title="twalergraph.jpg"> <span class="anchor" id="line-26"></span><span class="anchor" id="line-27"></span></p><p class="line862">The process ran on snorg.cs.ucla.edu is slightly more complex to deal with problems with scale. See <a href="http://wiki.cs.ucla.edu/twaler#Twaler_Process">Twaler Process</a> <span class="anchor" id="Files"></span> <span class="anchor" id="line-28"></span><span class="anchor" id="line-29"></span></p><p class="line867">
</p><h2 id="Files-1">Files</h2>
<span class="anchor" id="line-30"></span><p class="line874">There are the following files in the twaler src directory: <span class="anchor" id="line-31"></span><span class="anchor" id="line-32"></span></p><ul><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#crawl.py">crawl.py</a> <span class="anchor" id="line-33"></span></p></li><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#process_crawl.py">process_crawl.py</a> <span class="anchor" id="line-34"></span></p></li><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#load_crawl.py">load_crawl.py</a> <span class="anchor" id="line-35"></span></p></li><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#generate_seeds.py">generate_seeds.py</a> <span class="anchor" id="line-36"></span></p></li><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#config.py">config.py</a> <span class="anchor" id="line-37"></span></p></li><li><p class="line891"><a href="http://wiki.cs.ucla.edu/twaler#twaler.py">twaler.py</a> <span class="anchor" id="line-38"></span><span class="anchor" id="line-39"></span></p></li></ul><p class="line867"><span class="anchor" id="crawl.py"></span> <span class="anchor" id="line-40"></span><span class="anchor" id="line-41"></span></p><p class="line867">
</p><h3 id="crawl.py-1">crawl.py</h3>
<span class="anchor" id="line-42"></span><ul><li>Description: goes through the list of seeds in the seed file, downloading info for each id <span class="anchor" id="line-43"></span><ul><li><p class="line862">Usage:  ./crawl.py &lt;parameters&gt; &lt;config_file&gt; <span class="anchor" id="line-44"></span></p></li><li>We can manually specify parameters e.g) ./crawl.py --dir_log=log config.txt <span class="anchor" id="line-45"></span></li><li>Config file contains the parameters listed below, exactly in the: key= value format <span class="anchor" id="line-46"></span><ul><li>Parameters: <span class="anchor" id="line-47"></span><ul><li>seed-file = seedfile.txt <span class="anchor" id="line-48"></span></li><li>dir_log= logs <span class="anchor" id="line-49"></span><ul><li>folder to write logs to <span class="anchor" id="line-50"></span></li></ul></li><li>dir_cache= cache <span class="anchor" id="line-51"></span><ul><li>disk location of crawl results <span class="anchor" id="line-52"></span></li></ul></li><li>twitter_user= snorguser <span class="anchor" id="line-53"></span><ul><li>username for authentication required crawls <span class="anchor" id="line-54"></span></li></ul></li><li>twitter_password= snorg321 <span class="anchor" id="line-55"></span><ul><li>password for authentication required crawls <span class="anchor" id="line-56"></span></li></ul></li><li>crawl_numOfThreads= 10 <span class="anchor" id="line-57"></span><ul><li>number of threads used for downloading <span class="anchor" id="line-58"></span></li></ul></li></ul></li></ul></li></ul></li><li>Current Data Crawled <span class="anchor" id="line-59"></span><ul><li>User info <span class="anchor" id="line-60"></span></li><li>Tweets <span class="anchor" id="line-61"></span></li><li>Friends <span class="anchor" id="line-62"></span></li><li>List Memberships <span class="anchor" id="line-63"></span></li><li>Lists (*requires specification in seed file) <span class="anchor" id="line-64"></span><span class="anchor" id="line-65"></span></li></ul></li><li class="gap">Seedfile Format: <span class="anchor" id="line-66"></span><ul><li>Basic Usage: seed_file contains a list of user_ids <span class="anchor" id="line-67"></span><ul><li>e.g.)      1234567 <span class="anchor" id="line-68"></span><ul><li style="list-style-type: none;">7654321 … <span class="anchor" id="line-69"></span></li></ul></li><li>The crawler will crawl everything available for the user <span class="anchor" id="line-70"></span></li></ul></li><li>Advanced Usage: for specific crawls <span class="anchor" id="line-71"></span><ul><li>Crawling Users: <span class="anchor" id="line-72"></span><ul><li><p class="line891">&lt;crawl_targets&gt;\{tab}&lt;user_id&gt; &lt;optional:last_cursor&gt; <span class="anchor" id="line-73"></span></p></li><li>crawl targets: <span class="anchor" id="line-74"></span><ul><li>t: tweets <span class="anchor" id="line-75"></span></li><li>f: friends <span class="anchor" id="line-76"></span></li><li>m: list memberships <span class="anchor" id="line-77"></span></li></ul></li><li>Examples: <span class="anchor" id="line-78"></span><ul><li><p class="line862">tf\{tab}123456 =&gt; crawls the tweets and friends of 123456 <span class="anchor" id="line-79"></span></p></li><li><p class="line862">*\{tab}123456
987654321 =&gt; crawls the tweets, friends, list memberships of the
user_id, the argument is the “last_cursor”. By specifying the last
tweet id crawled from this user, we can avoid re-downloading tweets
that we have seen before <span class="anchor" id="line-80"></span></p></li></ul></li></ul></li><li>Crawling Lists: crawling lists are a trickier special case, we need the user_id of the owner and the list_id <span class="anchor" id="line-81"></span><ul><li><p class="line862">l\{tab}&lt;user_id&gt; &lt;list_id&gt; <span class="anchor" id="line-82"></span></p></li><li>Example: <span class="anchor" id="line-83"></span><ul><li><p class="line862">l\{tab}1234567 45678 =&gt;crawls list 45678 from user 1234567 <span class="anchor" id="line-84"></span></p></li><li>*this is getting simplified soon <span class="anchor" id="line-85"></span></li></ul></li></ul></li></ul></li></ul></li><li><p class="line862">Cache Folder Format: See <a href="http://wiki.cs.ucla.edu/twaler#cache_accessor.py">cache_accessor.py</a> <span class="anchor" id="line-86"></span><span class="anchor" id="line-87"></span></p></li></ul><p class="line867"><span class="anchor" id="process_crawl.py"></span> <span class="anchor" id="line-88"></span><span class="anchor" id="line-89"></span></p><p class="line867">
</p><h3 id="process_crawl.py-1">process_crawl.py</h3>
<span class="anchor" id="line-90"></span><ul><li>Description: parses the raw xml files from the dir_cache specified and produces tsv files for each table <span class="anchor" id="line-91"></span><ul><li><p class="line862">Usage:  ./process_crawl.py &lt;parameters&gt; &lt;config_file&gt; <span class="anchor" id="line-92"></span></p><ul><li>Parameters: <span class="anchor" id="line-93"></span><ul><li><p class="line862">instance= &lt;defaults to current time&gt; <span class="anchor" id="line-94"></span></p><ul><li>timestamp that represents the crawl instance <span class="anchor" id="line-95"></span></li></ul></li><li>dir_log= log <span class="anchor" id="line-96"></span><ul><li>disk directory location to write logs to <span class="anchor" id="line-97"></span></li></ul></li><li>dir_cache= cache <span class="anchor" id="line-98"></span><ul><li>disk directory location of crawl results <span class="anchor" id="line-99"></span></li></ul></li><li>dir_processed= processed_crawl <span class="anchor" id="line-100"></span><ul><li>directory to write processed tsv files to (if process_to_db=1, then this will not be created) <span class="anchor" id="line-101"></span></li></ul></li><li>process_to_db= 0 <span class="anchor" id="line-102"></span><ul><li>directly insert into MySQL DB (slow, must provide db info) <span class="anchor" id="line-103"></span></li></ul></li><li>db_server= localhost <span class="anchor" id="line-104"></span><ul><li>server for processing crawl results to MySQL DB (if process_to_db=1) <span class="anchor" id="line-105"></span></li></ul></li><li>db_database= twaler <span class="anchor" id="line-106"></span><ul><li>database for processing crawl results to MySQL DB (if process_to_db=1) <span class="anchor" id="line-107"></span></li></ul></li><li>db_username= snorgadmin <span class="anchor" id="line-108"></span><ul><li>MySQL DB username (if process_to_db=1) <span class="anchor" id="line-109"></span></li></ul></li><li>db_password= snorg321 <span class="anchor" id="line-110"></span><ul><li>MySQL DB password (if process_to_db=1) <span class="anchor" id="line-111"></span></li></ul></li><li>process_userinfo= 0 <span class="anchor" id="line-112"></span></li><li>process_friends= 0 <span class="anchor" id="line-113"></span></li><li>process_memberships= 0 <span class="anchor" id="line-114"></span></li><li>process_tweets= 0 <span class="anchor" id="line-115"></span></li><li>process_listmembers= 0 <span class="anchor" id="line-116"></span></li><li>extract_mentions= 0 <span class="anchor" id="line-117"></span></li><li>extract_urls= 0 <span class="anchor" id="line-118"></span></li><li>extract_hash= 0 <span class="anchor" id="line-119"></span></li></ul></li></ul></li></ul></li><li>tsv files are created exactly according to the twaler schema <span class="anchor" id="line-120"></span><span class="anchor" id="line-121"></span></li></ul><p class="line867"><span class="anchor" id="load_crawl.py"></span> <span class="anchor" id="line-122"></span><span class="anchor" id="line-123"></span></p><p class="line867">
</p><h3 id="load_crawl.py-1">load_crawl.py</h3>
<span class="anchor" id="line-124"></span><ul><li>Description: <span class="anchor" id="line-125"></span><ul><li><p class="line862">Usage: ./load_crawl.py [manual parameters] &lt;config file&gt;\n <span class="anchor" id="line-126"></span></p><ul><li>Parameters <span class="anchor" id="line-127"></span><ul><li>dir_log= log <span class="anchor" id="line-128"></span><ul><li>disk location to write logs to <span class="anchor" id="line-129"></span></li></ul></li><li>dir_processed= data <span class="anchor" id="line-130"></span><ul><li>directory where processed tsv are <span class="anchor" id="line-131"></span></li></ul></li><li>db_server= localhost <span class="anchor" id="line-132"></span><ul><li>server for processing crawl results to MySQL DB <span class="anchor" id="line-133"></span></li></ul></li><li>db_database= twaler <span class="anchor" id="line-134"></span><ul><li>database for processing crawl results to MySQL DB <span class="anchor" id="line-135"></span></li></ul></li><li>db_username= snorgadmin <span class="anchor" id="line-136"></span><ul><li>MySQL DB username <span class="anchor" id="line-137"></span></li></ul></li><li>db_password= snorg321 <span class="anchor" id="line-138"></span><ul><li>MySQL DB password <span class="anchor" id="line-139"></span><span class="anchor" id="line-140"></span></li></ul></li></ul></li></ul></li></ul></li></ul><p class="line867"><span class="anchor" id="config.py"></span> <span class="anchor" id="line-141"></span><span class="anchor" id="line-142"></span></p><p class="line867">
</p><h3 id="config.py-1">config.py</h3>
<span class="anchor" id="line-143"></span><ul><li>A header that contains the following helper functions: <span class="anchor" id="line-144"></span><ul><li><p class="line891"><strong>logger</strong>: a class that specifies the format and output stream to which to print the log to. All classes use this. <span class="anchor" id="line-145"></span></p></li><li><p class="line891"><strong>Timefunctions</strong>: a group of static functions simply used to convert various time formats between each other <span class="anchor" id="line-146"></span></p></li><li><p class="line891"><strong>Cache_accessor</strong>:
a wrapper that manages the way crawled data are stored onto disk.
During each crawl instance, we may go through up to 20,000 users and
generate a larger number of files (in zipped XML format). The
cache_accessor organizes files by generating a directory for each user
id. To avoid the case where a folder has 20,000 directory under it, the
cache_accessor also generates intermediate directories by hashing the
last three digits of each user id. For the caller function, the caller
can simply call to either insert or obtain all the files of a
particular user id. The cache_accessor also allows the caller to
iterate through all the users under a specific directory. <span class="anchor" id="line-147"></span></p><ul><li>Example: <span class="anchor" id="line-148"></span><ul><li><p class="line862">User 1234567 is stored in the cache directory under: <em>cache/7/6/5/1234567</em> <span class="anchor" id="line-149"></span></p></li></ul></li></ul></li><li><p class="line891"><strong>Mysql_db</strong>: a wrapper that allows the user to perform MySQL inserts/lookups to a specified MySQL databased and table. <span class="anchor" id="line-150"></span></p></li><li><p class="line891"><strong>File_db</strong>:
a wrapper that allows the user to perform inserts to a file using the
same interface of Mysql_db. This is created primarily to provide an
alternative to using the default MySQL database as the storage system.
This class is also used in process_crawl to generate tsv files to load
to the MySQL database. <span class="anchor" id="line-151"></span></p></li><li><p class="line891"><strong>Parse_arguments</strong>: a function that parses both command-line arguments and arguments from the configuration file. <span class="anchor" id="line-152"></span><span class="anchor" id="line-153"></span></p></li></ul></li></ul><p class="line867"><span class="anchor" id="twaler.py"></span> <span class="anchor" id="line-154"></span><span class="anchor" id="line-155"></span></p><p class="line867">
</p><h3 id="twaler.py-1">twaler.py</h3>
<span class="anchor" id="line-156"></span><ul><li>Twaler executes the
entire process, runs each component accordingly, and keeps the entire
process synchronized. Twaler begins by detecting seed files under the
specified directory. If a seed file exists, Twaler then generates a
crawl instance, in which the seed file will be crawled, processed, and
the results loaded into the database. This process continues until all
the seed files in the seed directory have been crawled and processed.
In this case, Twaler will call the generate seed component to generate
new seeds and fill the seed directory, and restart the process all over
again <span class="anchor" id="line-157"></span><span class="anchor" id="line-158"></span></li><li class="gap" style="list-style-type: none;"><p class="line891"><img alt="twaler_state_diagram.jpg" class="attachment" src="twaler_files/twaler_002.jpeg" title="twaler_state_diagram.jpg"> <span class="anchor" id="line-159"></span><span class="anchor" id="line-160"></span></p></li></ul><p class="line867"><span class="anchor" id="Usage_Example"></span> <span class="anchor" id="line-161"></span><span class="anchor" id="line-162"></span></p><p class="line867">
</p><h2 id="Usage_Example-1">Usage Example</h2>
<span class="anchor" id="line-163"></span><p class="line874">How to start from scratch and start crawling Twitter data: <span class="anchor" id="line-164"></span></p><ol type="1"><li>Unzip twaler.tar <span class="anchor" id="line-165"></span></li><li>The unzipped folder should contain the following: <span class="anchor" id="line-166"></span><ol type="a"><li><p class="line891"><em>config.txt</em>:
contains the recommended/default parameters to run Twaler. You may
change this accordingly (read the documentation on parameters for each
component for details) <span class="anchor" id="line-167"></span></p></li><li><p class="line891"><em>scripts/</em>: contains scripts for setting up your own MySQL database according to the Twaler schema <span class="anchor" id="line-168"></span></p><ol type="i"><li><p class="line891"><em>twaler_schema.sql</em>: generates the schema according to the schema specified in Twaler DB <span class="anchor" id="line-169"></span></p></li></ol></li><li><p class="line891"><em>seeds/</em>: seed files in this directory will be crawled. Contains an <em>init_seed.txt</em> with an initial single seed. <span class="anchor" id="line-170"></span></p></li><li><p class="line891"><em>seedsdone/</em>: once a seed file is completed, it will be sent here <span class="anchor" id="line-171"></span>a.<em>src/</em>: Contains all of the python programs required to run the system. <span class="anchor" id="line-172"></span></p></li></ol></li><li><p class="line862">To run: under the unzipped directory, type: <em>python src/twaler.py config.txt</em>. This initiates the crawl using the initial seed under the seeds. <span class="anchor" id="line-173"></span></p></li><li>Once the crawl begins, the screen should display information as shown below to inform you of the status of the crawl. <span class="anchor" id="line-174"></span></li></ol><p class="line867"><img alt="tut1.png" class="attachment" src="twaler_files/twaler.png" title="tut1.png"> <span class="anchor" id="line-175"></span></p><ul><li><p class="line862">the item inside the brackets <em>ie)[Crawler], [process_crawl]]</em> indicate the process of the crawl.  <span class="anchor" id="line-176"></span></p></li><li><p class="line891"><em>[Worker #]</em> indicates each thread from the crawler <span class="anchor" id="line-177"></span><span class="anchor" id="line-178"></span></p></li></ul><ol type="5"><li>Some new folders are created as the crawl progresses: <span class="anchor" id="line-179"></span><ol type="a"><li><p class="line891"><em>cache/</em>: <span class="anchor" id="line-180"></span></p><ol type="i"><li><p class="line891"><em>date-instances/</em>: each crawl instance is defined by the time when the crawl begins ie)<em>2010.08.01.00.00.00</em> <span class="anchor" id="line-181"></span></p><ol type="I"><li><p class="line891"><em>0/,1/,2/...9/</em>: these are folders that contain the raw Twitter data from this particular crawl <span class="anchor" id="line-182"></span></p></li><li><p class="line891"><em>log/</em>: this folder contains the logs for this particular crawl <span class="anchor" id="line-183"></span></p></li><li><p class="line891"><em>processed_crawl/</em>: contains the processed tsv files from the raw data <span class="anchor" id="line-184"></span></p></li><li><p class="line891"><em>seed_file.txt</em>: the seed used in this particular crawl <span class="anchor" id="line-185"></span></p></li></ol></li></ol></li><li><p class="line891"><em>log/</em>: logs from the twaler process <span class="anchor" id="line-186"></span></p></li></ol></li><li>The Twaler database is also populated in each instance <span class="anchor" id="line-187"></span><span class="anchor" id="line-188"></span><span class="anchor" id="line-189"></span></li></ol><p class="line867"><span class="anchor" id="Getting_the_Latest_Version"></span> <span class="anchor" id="line-190"></span><span class="anchor" id="line-191"></span></p><p class="line867">
</p><h2 id="Getting_the_Latest_Version-1">Getting the Latest Version</h2>
<span class="anchor" id="line-192"></span><span class="anchor" id="bottom"></span></div><p id="pageinfo" class="info" dir="ltr" lang="en">twaler  (last edited 2010-08-03 00:57:21 by <span title="AlexanderLiu @ c-98-234-104-104.hsd1.ca.comcast.net[98.234.104.104]"><a class="nonexistent" href="http://wiki.cs.ucla.edu/AlexanderLiu" title="AlexanderLiu @ c-98-234-104-104.hsd1.ca.comcast.net[98.234.104.104]">AlexanderLiu</a></span>)</p>

<div id="pagebottom"></div>
</div>


<div id="footer">
<ul class="editbar"><li><a href="http://wiki.cs.ucla.edu/twaler?action=edit&amp;editor=text" name="texteditlink" rel="nofollow">Edit (Text)</a></li><li><a href="http://wiki.cs.ucla.edu/twaler?action=edit&amp;editor=gui">Edit (GUI)</a></li><li class="toggleCommentsButton" style="display: none;"><a href="#" class="nbcomment" onclick="toggleComments();return false;">Comments</a></li><li><a class="nbinfo" href="http://wiki.cs.ucla.edu/twaler?action=info" rel="nofollow">Info</a></li><li><a class="nbsubscribe" href="http://wiki.cs.ucla.edu/twaler?action=subscribe" rel="nofollow">Subscribe</a></li><li><a class="nbquicklink" href="http://wiki.cs.ucla.edu/twaler?action=quicklink" rel="nofollow">Add Link</a></li><li><a class="nbattachments" href="http://wiki.cs.ucla.edu/twaler?action=AttachFile" rel="nofollow">Attachments</a></li><li>
<form class="actionsmenu" method="get" action="/twaler">
<div>
    
    <select name="action" onchange="if ((this.selectedIndex != 0) &amp;&amp;
                      (this.options[this.selectedIndex].disabled == false)) {
                this.form.submit();
            }
            this.selectedIndex = 0;">
        <option value="show">More Actions:</option><option value="raw">Raw Text</option>
<option value="print">Print View</option>
<option value="RenderAsDocbook">Render as Docbook</option>
<option value="refresh">Delete Cache</option>
<option value="show" disabled="disabled" class="disabled">------------------------</option>
<option value="SpellCheck">Check Spelling</option>
<option value="LikePages">Like Pages</option>
<option value="LocalSiteMap">Local Site Map</option>
<option value="show" disabled="disabled" class="disabled">------------------------</option>
<option value="RenamePage">Rename Page</option>
<option value="DeletePage">Delete Page</option>
<option value="show" disabled="disabled" class="disabled">------------------------</option>
<option value="SubscribeUser">Subscribe User</option>
<option value="show" disabled="disabled" class="disabled">------------------------</option>
<option value="show" disabled="disabled" class="disabled">Remove Spam</option>
<option value="revert">Revert to this revision</option>
<option value="PackagePages">Package Pages</option>
<option value="SyncPages">Sync Pages</option>
<option value="show" disabled="disabled" class="disabled">------------------------</option>
<option value="Load">Load</option>
<option value="Save">Save</option>
<option value="SlideShow">SlideShow</option>
    </select>
    
    
</div>
<script type="text/javascript">
<!--// Init menu
actionsMenuInit('More Actions:');
//-->
</script>
</form>
</li></ul>

<ul id="credits">
<li><a href="http://moinmo.in/" title="This site uses the MoinMoin Wiki software.">MoinMoin Powered</a></li><li><a href="http://moinmo.in/Python" title="MoinMoin is written in Python.">Python Powered</a></li><li><a href="http://moinmo.in/GPL" title="MoinMoin is GPL licensed.">GPL licensed</a></li><li><a href="http://validator.w3.org/check?uri=referer" title="Click here to validate this page.">Valid HTML 4.01</a></li>
</ul>


</div>
</body></html>